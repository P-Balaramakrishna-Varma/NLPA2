{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_file, vocab_index, pos_tag_index):\n",
    "    TokenLists = conllu.parse_incr(open(data_file, \"r\", encoding=\"utf-8\"))\n",
    "    Sentences = []\n",
    "    Tag_Sequences = []\n",
    "    for TokenList in TokenLists:\n",
    "        Sentence = []\n",
    "        tags = []\n",
    "        for token in TokenList:\n",
    "            #print(token[\"form\"], token[\"upos\"])\n",
    "            Sentence.append(vocab_index[token[\"form\"]])\n",
    "            tags.append(pos_tag_index[token[\"upos\"]])\n",
    "        Sentences.append(Sentence)\n",
    "        Tag_Sequences.append(tags)\n",
    "    return Sentences, Tag_Sequences\n",
    "\n",
    "\n",
    "def get_vocab_index(data_file):\n",
    "    vocab_index = {}\n",
    "    TokenLists = conllu.parse_incr(open(data_file, \"r\", encoding=\"utf-8\"))\n",
    "    for TokenList in TokenLists:\n",
    "        for token in TokenList:\n",
    "            if token[\"form\"] not in vocab_index:\n",
    "                vocab_index[token[\"form\"]] = len(vocab_index)\n",
    "    return vocab_index\n",
    "\n",
    "\n",
    "def custom_collate(batch):\n",
    "    Sentences = [sample[0] for sample in batch]\n",
    "    PosTags = [sample[1] for sample in batch]\n",
    "\n",
    "    Sentences = pad_sequence(Sentences, batch_first=True)\n",
    "    PosTags = pad_sequence(PosTags, batch_first=True)\n",
    "    return Sentences, PosTags\n",
    "\n",
    "\n",
    "class PosTagDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.vocab_index = get_vocab_index(data_file)\n",
    "        self.pos_tag_index = { \"ADJ\": 0, \"ADP\": 1, \"ADV\": 2, \"AUX\": 3, \"CCONJ\": 4, \"DET\": 5, \"INTJ\": 6, \"NOUN\": 7, \"NUM\": 8, \"PART\": 9, \"PRON\": 10, \"PROPN\": 11, \"PUNCT\": 12, \"SCONJ\": 13, \"SYM\": 14, \"VERB\": 15, \"X\": 16}\n",
    "        self.Sentences, self.Tag_Sequences = get_data(data_file, vocab_index, pos_tag_index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.Sentences[idx]), torch.LongTensor(self.Tag_Sequences[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"./UD_English-Atis/en_atis-ud-dev.conllu\"\n",
    "\n",
    "vocab_index = get_vocab_index(data_file)\n",
    "pos_tag_index = { \"ADJ\": 0, \"ADP\": 1, \"ADV\": 2, \"AUX\": 3, \"CCONJ\": 4, \"DET\": 5, \"INTJ\": 6, \"NOUN\": 7, \"NUM\": 8, \"PART\": 9, \"PRON\": 10, \"PROPN\": 11, \"PUNCT\": 12, \"SCONJ\": 13, \"SYM\": 14, \"VERB\": 15, \"X\": 16}\n",
    "\n",
    "Sentences, Tag_Sequences = get_data(data_file, vocab_index, pos_tag_index)\n",
    "\n",
    "\n",
    "for i in range(len(Sentences)):\n",
    "    for j in range(len(Sentences[i])):\n",
    "        print(Sentences[i][j], Tag_Sequences[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PosTagDataset(data_file)\n",
    "print(dataset[0])\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=custom_collate)\n",
    "for batch in train_dataloader:\n",
    "    print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "065fb8b657f91755f4fa62e8fa2cb5eae56030de00e55e0c25fcdec87b4196ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
